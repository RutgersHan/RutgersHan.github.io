
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Notes for &lt;Visualizing and Understanding Convolutional Networks&gt; | Be a geek</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Han Zhang">
    

    
    <meta name="description" content="A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features does the opposite.Original PaperOne impleme">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes for <Visualizing and Understanding Convolutional Networks>">
<meta property="og:url" content="https://RutgersHan.github.io/2015/05/13/Notes-for-Visualizing-and-Understanding-Convolutional-Networks/index.html">
<meta property="og:site_name" content="Be a geek">
<meta property="og:description" content="A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features does the opposite.Original PaperOne impleme">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.07.48 AM.png">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.45.26 AM.png">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.51.09 AM.png">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.53.32 AM.png">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.53.56 AM.png">
<meta property="og:image" content="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 2.06.30 AM.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Notes for <Visualizing and Understanding Convolutional Networks>">
<meta name="twitter:description" content="A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features does the opposite.Original PaperOne impleme">

    
    <link rel="alternative" href="/atom.xml" title="Be a geek" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/victor.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/victor.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="Be a geek" title="Be a geek"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Be a geek">Be a geek</a></h1>
				<h2 class="blog-motto">梦想一定要有的，万一见鬼了呢</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:RutgersHan.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/13/Notes-for-Visualizing-and-Understanding-Convolutional-Networks/" title="Notes for &lt;Visualizing and Understanding Convolutional Networks&gt;" itemprop="url">Notes for &lt;Visualizing and Understanding Convolutional Networks&gt;</a>
  </h1>
  <p class="article-author">By
       
		<a href="https://RutgersHan.github.io/about" title="Han Zhang" target="_blank" itemprop="author">Han Zhang</a>
		
  <p class="article-time">
    <time datetime="2015-05-13T04:51:14.000Z" itemprop="datePublished"> 发表于 2015-05-13</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline"><span class="toc-number">1.</span> <span class="toc-text">Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Some_findings"><span class="toc-number">2.</span> <span class="toc-text">Some findings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments"><span class="toc-number">3.</span> <span class="toc-text">Experiments</span></a></li></ol>
		
		</div>
		
		<p>A deconvnet can be thought of as a convnet model that uses the same components (filtering, pooling) but in reverse, so instead of mapping pixels to features does the opposite.<br><a href="http://ftp.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="external">Original Paper</a><br><a href="https://github.com/ChienliMa/DeConvNet" target="_blank" rel="external">One implementation</a><br><a href="https://chienlima.wordpress.com/2014/07/25/visualization-i-introduction/" target="_blank" rel="external">One blog</a></p>
<a id="more"></a>
<h3 id="Pipeline">Pipeline</h3><p>An input image is presented to the convnet and features computed throughout the layers. To examine a given convnet activation, we set all other activations in the layer to zero and pass the feature maps as input to the attached deconvnet layer. Then we successively<br>(i) unpool, (ii) rectify and (iii) filter to reconstruct the activity in the layer beneath that gave rise to the chosen activation.This is then repeated until input pixel space is reached.<br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.07.48 AM.png" alt=""></p>
<ol>
<li><p>Unpooling: save the switches in the pooling and in unpooling, using switches which record the<br>location of the local max in each pooling region and set the other locations to be zero. See the above image</p>
</li>
<li><p>Rectification: after the unpooling(actually it is form the deconv in the above), the feature map could have negative values. But the original RELU layer are all &gt;=0. To match that, we pass the reconstruction value to RELU.</p>
</li>
<li><p>Filtering(deconv): The convnet uses learned filters to convolve the feature maps from the previous layer. To invert this, the deconvnet uses transposed versions ofthe same filters, but applied to the rectified maps, not the output of the layer beneath. In practice this means <strong>flipping each filter vertically and horizontally</strong>.</p>
</li>
</ol>
<h3 id="Some_findings">Some findings</h3><ol>
<li><p><strong>Feature Visualization</strong>: (In the images, showed in this paper.For each neuron, find the images in the validation which have top 9 activation sccores, use the deconv net to propogate back to the original image and also the correspoing patch). We can see that layer 2,3,4 seem to discribe attributes. </p>
</li>
<li><p><strong>Feature Evolution during Training</strong>: The lower layers of the model can be seen to converge within a few epochs. However, the upper layers only develop develop after a considerable number of epochs (40-50)</p>
</li>
<li><p><strong>Feature Invariance</strong>: images being translated, rotated and scaled by varying degrees while looking at the changes in the feature vectors from the top and bottom layers of the model, relative to the untransformed feature. Small transformations have a<br>dramatic effect in the first layer of the model, but a lesser impact at the top feature layer,  being quasilinear<br>for translation &amp; scaling. The network output is stable to translations and scalings. In general, <strong>the output is not invariant to rotation</strong></p>
</li>
<li><p><strong>Architecture Selection</strong>: While visualization of a trained model gives insight into its operation, it can also assist with selecting good architectures in the first place. E.g. t. The first layer filters are a mix of extremely high and low frequency information, with little coverage of the mid frequencies. Additionally, the 2nd layer visualization shows <strong>aliasing artifacts</strong> caused by the large stride 4 used in the 1st layer convolutions. To remedy these problems, we (i) reduced the 1st layer filter size from 11x11 to 7x7 and (ii) made the stride of the convolution 2, rather than 4. It improves  the classification performance</p>
</li>
<li><p><strong>Occlusion Sensitivity</strong>: Answer <em>whether the model is truly identifying the location of the object in the image, or just using the surrounding context?</em>occluding different portions of the input image with a grey square, and monitoring the output of the classifier.<br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.45.26 AM.png" alt=""></p>
</li>
<li><strong>Correspondence Analysis</strong>: Answer <em>whether CNN can model correspondence between specific object parts in different images</em>. we take 5 randomly drawn dog images with frontal pose and systematically mask out the same part of the face in each image. Then computer the difference of feature vectors at layer l original and occluded images respectively<br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.51.09 AM.png" alt=""></li>
</ol>
<h3 id="Experiments">Experiments</h3><ol>
<li>Accoridng to the visualizetion to change the structure, improves the classfication accuracy for ImageNet 2012</li>
<li>Varying the model size: by adjusting the size of layers, or removing them entirely. Removing the fully connected layers (6,7) only gives a slight increase in error. ). This is surprising, given that they contain the majority of model parameters. Removing two of the middle convolutional layers also makes a relatively small difference to the error rate. However, removing both the middle convolution layers and the fully connected layers yields a model with only 4 layers whose performance is dramatically worse. This would suggest that the overall depth of the model is important for obtaining good performance. We then modify our model, shown in Fig. 3. Changing the size of the fully connected layers makes little difference to performance (same for model of Krizhevsky et al. [18]). However, increasing the size of the middle convolution layers goes give a useful gain in performance. But increasing these, while also enlarging the fully connected layers results in over-fitting.<br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.53.32 AM.png" alt=""><br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 1.53.56 AM.png" alt=""></li>
<li>Feature Generalization: Pretrain-Finetune works good in Caltech-101 and Caltech-256, not very good for PASCAL 2012. Since images in Imagenet and PASCAL are so different. </li>
<li>Feature Analysis:<br><img src="http://7xikhz.com1.z0.glb.clouddn.com/Screen Shot 2015-05-13 at 2.06.30 AM.png" alt=""></li>
</ol>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Research/">Research</a>
</div>


</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://RutgersHan.github.io/2015/05/13/Notes-for-Visualizing-and-Understanding-Convolutional-Networks/" data-title="Notes for &lt;Visualizing and Understanding Convolutional Networks&gt; | Be a geek" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/05/13/Notes-for-Deep-Inside-Convolutional-Networks-Visualising-Image-Classification-Models-and-Saliency-Maps/" title="Notes for&lt;Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps&gt;">
  <strong>上一篇：</strong><br/>
  <span>
  Notes for&lt;Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps&gt;</span>
</a>
</div>


<div class="next">
<a href="/2015/05/05/Minerva-A-New-Deep-Learning-Framework/"  title="Minerva: A New Deep Learning Framework">
 <strong>下一篇：</strong><br/> 
 <span>Minerva: A New Deep Learning Framework
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2015/05/13/Notes-for-Visualizing-and-Understanding-Convolutional-Networks/" data-title="Notes for <Visualizing and Understanding Convolutional Networks>" data-url="https://RutgersHan.github.io/2015/05/13/Notes-for-Visualizing-and-Understanding-Convolutional-Networks/"></div>
</section>


<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Pipeline"><span class="toc-number">1.</span> <span class="toc-text">Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Some_findings"><span class="toc-number">2.</span> <span class="toc-text">Some findings</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments"><span class="toc-number">3.</span> <span class="toc-text">Experiments</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/Engineering/" title="Engineering">Engineering<sup>5</sup></a></li>
		  
		
		  
			<li><a href="/categories/LeetCode/" title="LeetCode">LeetCode<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/Open-Course/" title="Open Course">Open Course<sup>17</sup></a></li>
		  
		
		  
			<li><a href="/categories/Research/" title="Research">Research<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/计划/" title="计划">计划<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书笔记/" title="读书笔记">读书笔记<sup>1</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Deep-Learning/" title="Deep Learning">Deep Learning<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/caffe/" title="caffe">caffe<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/LeetCode/" title="LeetCode">LeetCode<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/时间管理/" title="时间管理">时间管理<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Notes/" title="Notes">Notes<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Object-Detection/" title="Object Detection">Object Detection<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/deep-learning/" title="deep learning">deep learning<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Image-Caption-Generation/" title="Image Caption Generation">Image Caption Generation<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Han at Rutgers. <br/>
			Wanna be a geek, let&#39;s learn together</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2015 
		
		<a href="https://RutgersHan.github.io/about" target="_blank" title="Han Zhang">Han Zhang</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#nothing"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>



<script type="text/javascript">
  var duoshuoQuery = {short_name:"zhanghan"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 


<script type="text/javascript">

var disqus_shortname = 'zhanghan';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
